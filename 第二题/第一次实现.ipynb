{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e92a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\.conda\\envs\\pytorch2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: fashion-mnist\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " torchvision.datasets.mnist.FashionMNIST)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据\n",
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "def load_data():\n",
    "    dataset=torchvision.datasets.FashionMNIST(root=\"fashion-mnist\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "    return dataset\n",
    "#初始化数据集\n",
    "dataset=load_data()\n",
    "len(dataset),dataset,type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fd0e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312,\n",
       " torch.Size([32, 784]),\n",
       " tensor([6, 6, 0, 1, 0, 1, 7, 2, 8, 3, 1, 3, 1, 0, 8, 2, 9, 7, 5, 2, 8, 9, 2, 4,\n",
       "         5, 2, 2, 5, 5, 5, 4, 8]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据集加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=32,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "len(loader), x.reshape(-1,784).shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a20247",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (u): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (v): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (LogSoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nn.Linear实现RNN神经网络\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.u = torch.nn.Linear(784, 256)#定义输入层\n",
    "        self.w = torch.nn.Linear(256, 256)#定义隐藏层\n",
    "        self.v = torch.nn.Linear(256, 10)#定义输出层\n",
    "        self.tanh = torch.nn.Tanh()#激活函数\n",
    "        self.LogSoftmax = torch.nn.LogSoftmax(dim=1)#定义归一化函数，对应了torch.nn.NLLLoss()\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        \n",
    "        u_x = self.u(inputs)#输入层\n",
    "        hidden = self.w(hidden)#获取上一个隐藏层\n",
    "        hidden = self.tanh(hidden + u_x)#隐藏层和输入相加传入激活函数，并更新隐藏层\n",
    "        output = self.LogSoftmax(self.v(hidden))#归一化输出\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):#初始化隐藏层\n",
    "        return torch.zeros(1, 256)\n",
    "\n",
    "rnn=RNN()\n",
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233d2672",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#训练\n",
    "rnn.cuda()\n",
    "import tqdm\n",
    "def train():\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=1e-4)\n",
    "    \n",
    "    criterion = torch.nn.NLLLoss()#\n",
    "    rnn.train()\n",
    "    \n",
    "    bar=tqdm.tqdm(range(5))\n",
    "    hidden=rnn.initHidden().cuda()\n",
    "    hidden = hidden.cuda()\n",
    "    \n",
    "    for epoch in bar:\n",
    "        #rnn.zero_grad()\n",
    "        for i ,( x , y )in enumerate(loader):\n",
    "            x=x.reshape(-1,784).cuda()\n",
    "            y=y.cuda()\n",
    "            output, hidden = rnn(x, hidden)\n",
    "            loss = criterion(output,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            \"\"\"在PyTorch中，当你执行.backward()方法时，计算图上的所有中间张量都会被释放，\n",
    "            以节省内存。如果你需要多次进行反向传播，或者在反向传播后需要访问这些中间张量，\n",
    "            你需要设置retain_graph=True参数。\"\"\"\n",
    "            for p in rnn.parameters():\n",
    "                #p.data.add_(-learning_rate, p.grad.data)\n",
    "                p.data-=learning_rate*p.grad.data\n",
    "            optimizer.zero_grad()\n",
    "        #求一个batch内各指标并累加\n",
    "        target_label=7#自定义正例，其他为负例\n",
    "        TP=TN=FP=FN=0\n",
    "        j=0\n",
    "        for x in output.argmax(dim=1):\n",
    "            if x==target_label and y[j]==target_label:\n",
    "                TP+=1\n",
    "            elif x==target_label and y[j]!=target_label:\n",
    "                FP+=1\n",
    "            elif x!=target_label and y[j]!=target_label:\n",
    "                TN+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "            j+=1\n",
    "        accuracy=(TP+TN)/(TP+TN+FP+FN)if (TP+TN+FP+FN) > 0 else 0\n",
    "        precision=TP/(TP+FP)if (TP + FP) > 0 else 0\n",
    "        recall=TP/(TP+FN)if (TP + FN) > 0 else 0\n",
    "        F1=2*(precision*recall)/(precision+recall)if (precision+recall) > 0 else 0\n",
    "        print(epoch, loss.item())\n",
    "        print(f\"accuracy={accuracy}\")\n",
    "        print(f\"precision={precision}\")\n",
    "        print(f\"recall={recall}\")\n",
    "        print(f\"F1={F1}\")\n",
    "\n",
    "            # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77901c01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████▊                                               | 1/5 [00:10<00:43, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.049337387084961\n",
      "accuracy=0.9375\n",
      "precision=0.5\n",
      "recall=1.0\n",
      "F1=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████▌                                   | 2/5 [00:39<01:03, 21.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.8257420063018799\n",
      "accuracy=0.90625\n",
      "precision=0.4\n",
      "recall=1.0\n",
      "F1=0.5714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████▍                       | 3/5 [01:25<01:05, 32.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.7598148584365845\n",
      "accuracy=0.84375\n",
      "precision=0.375\n",
      "recall=1.0\n",
      "F1=0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████▏           | 4/5 [02:29<00:44, 44.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.4492310285568237\n",
      "accuracy=0.96875\n",
      "precision=0.8\n",
      "recall=1.0\n",
      "F1=0.888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 5/5 [03:54<00:00, 46.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.4595184326171875\n",
      "accuracy=0.9375\n",
      "precision=0.5\n",
      "recall=1.0\n",
      "F1=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.7020, -3.7757, -1.3965, -3.3789, -1.2160, -4.3824, -1.8359, -4.3601,\n",
       "          -2.1561, -3.4568],\n",
       "         [-3.2237, -4.0865, -2.2417, -3.3017, -1.7495, -2.9610, -2.5646, -2.6824,\n",
       "          -1.3594, -1.7574],\n",
       "         [-2.3162, -3.9882, -1.3741, -3.4135, -1.5232, -4.5005, -1.6902, -4.6081,\n",
       "          -2.0098, -3.2382],\n",
       "         [-1.0516, -2.2144, -2.2714, -2.0305, -2.6347, -3.9476, -2.0229, -4.2385,\n",
       "          -3.1694, -3.6041],\n",
       "         [-2.1569, -2.5852, -1.9317, -2.1133, -1.4627, -4.1311, -1.7927, -4.1966,\n",
       "          -2.5725, -3.2802],\n",
       "         [-3.9851, -4.5228, -3.1957, -3.8994, -3.3334, -2.5952, -3.5379, -2.9918,\n",
       "          -2.2922, -0.4801],\n",
       "         [-2.5842, -3.2309, -1.4868, -2.9565, -1.5768, -3.3446, -1.9271, -3.3343,\n",
       "          -1.9693, -3.1179],\n",
       "         [-2.8325, -2.8855, -2.7444, -2.5483, -2.7624, -1.8279, -2.6773, -1.7305,\n",
       "          -2.1155, -1.8814],\n",
       "         [-1.5340, -1.9725, -2.3816, -1.5976, -2.0983, -4.1551, -2.0463, -4.2279,\n",
       "          -3.1794, -3.6238],\n",
       "         [-2.6226, -3.4389, -1.5339, -2.9423, -1.5025, -3.8463, -1.8692, -3.9372,\n",
       "          -1.8790, -2.8747],\n",
       "         [-1.2599, -2.3728, -2.2312, -2.0596, -2.5368, -3.2294, -1.8149, -3.8007,\n",
       "          -2.8825, -3.5644],\n",
       "         [-1.9170, -1.1806, -3.2824, -1.0700, -3.0739, -4.3512, -2.8706, -4.4378,\n",
       "          -3.8209, -4.1487],\n",
       "         [-1.8797, -2.4064, -2.0663, -1.9596, -1.5790, -4.3569, -1.8359, -4.1099,\n",
       "          -2.6998, -3.5912],\n",
       "         [-3.4918, -4.2864, -2.2113, -3.5177, -2.0468, -2.8124, -2.6199, -2.8974,\n",
       "          -0.9690, -2.1211],\n",
       "         [-2.3155, -3.1564, -1.5626, -2.6748, -1.3455, -4.5804, -1.6994, -4.5478,\n",
       "          -2.3441, -3.9010],\n",
       "         [-2.6152, -3.7488, -1.4587, -3.3046, -1.1438, -4.6418, -1.8451, -4.4105,\n",
       "          -2.2242, -3.5941],\n",
       "         [-1.9566, -1.2556, -3.1118, -1.1117, -2.8452, -4.1470, -2.7785, -4.4378,\n",
       "          -3.4219, -3.9267],\n",
       "         [-2.1878, -3.0012, -1.9220, -2.7873, -2.0343, -2.5146, -1.8845, -2.9785,\n",
       "          -1.9155, -2.6810],\n",
       "         [-4.1487, -4.3210, -3.4194, -3.9186, -3.0721, -1.8658, -3.4407, -1.2049,\n",
       "          -2.0207, -1.3747],\n",
       "         [-3.4368, -4.6435, -2.1106, -4.2731, -1.9645, -2.7869, -2.6919, -2.2754,\n",
       "          -1.1430, -2.0256],\n",
       "         [-2.2163, -0.7752, -3.1148, -1.4197, -2.9968, -4.8580, -2.9548, -4.9313,\n",
       "          -4.3025, -4.2954],\n",
       "         [-3.3788, -3.3147, -2.7745, -3.2204, -2.8489, -1.4708, -2.9321, -1.6858,\n",
       "          -1.9290, -1.8596],\n",
       "         [-2.6920, -3.3886, -2.0878, -3.0560, -1.9604, -2.5429, -2.2881, -2.4970,\n",
       "          -1.6116, -2.0821],\n",
       "         [-2.5338, -1.7892, -2.7669, -1.8967, -2.6852, -1.8168, -2.4263, -2.4429,\n",
       "          -2.5963, -2.8124],\n",
       "         [-2.0169, -3.4375, -1.4431, -2.9713, -1.6053, -4.3242, -1.8212, -4.2254,\n",
       "          -2.1168, -3.3129],\n",
       "         [-2.6415, -2.9465, -1.9983, -2.7527, -1.9992, -2.1050, -2.0337, -2.4868,\n",
       "          -2.0520, -2.5626],\n",
       "         [-2.1217, -2.8174, -1.3283, -2.8419, -1.7878, -4.0915, -1.7147, -4.0470,\n",
       "          -2.6855, -3.0482],\n",
       "         [-3.7288, -3.7413, -3.2591, -3.5919, -2.8419, -1.6350, -3.2146, -1.1234,\n",
       "          -1.9059, -2.1288],\n",
       "         [-1.1079, -2.4807, -2.0527, -2.0152, -2.3356, -4.4685, -1.9012, -4.5761,\n",
       "          -3.3686, -3.8143],\n",
       "         [-3.1417, -4.4746, -1.8618, -4.0441, -1.6747, -3.3562, -2.3326, -2.9815,\n",
       "          -1.2316, -2.2014],\n",
       "         [-3.8249, -3.4316, -3.2587, -3.3779, -3.0048, -1.6624, -3.2336, -1.2853,\n",
       "          -2.1081, -1.6265],\n",
       "         [-2.4968, -3.2438, -1.2580, -2.9841, -1.3620, -4.7996, -1.8123, -4.2574,\n",
       "          -2.5666, -3.6807]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " 1.4595184326171875)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51f2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn, 'rnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1135ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9331931089743589\n",
      "precision=0.6152234636871509\n",
      "recall=0.8836509528585758\n",
      "F1=0.7254013997529848\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model = torch.load('rnn_model')\n",
    "    model.eval()\n",
    "    model=model.cuda()\n",
    "    hidden=rnn.initHidden()\n",
    "\n",
    "    target_label=7#自定义正例，其他为负例\n",
    "    TP=TN=FP=FN=0\n",
    "    #遍历整个数据集\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x=x.reshape(-1,784).cuda()\n",
    "        y=y.cuda()\n",
    "        hidden=hidden.cuda()\n",
    "        out,hidden = rnn(x,hidden)\n",
    "        #求一个batch内各指标并累加\n",
    "        j=0\n",
    "        for x in out.argmax(dim=1):\n",
    "            if x==target_label and y[j]==target_label:\n",
    "                TP+=1\n",
    "            elif x==target_label and y[j]!=target_label:\n",
    "                FP+=1\n",
    "            elif x!=target_label and y[j]!=target_label:\n",
    "                TN+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "            j+=1\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)if (TP+TN+FP+FN) > 0 else 0\n",
    "    precision=TP/(TP+FP)if (TP + FP) > 0 else 0\n",
    "    recall=TP/(TP+FN)if (TP+FN) > 0 else 0\n",
    "    F1=2*(precision*recall)/(precision+recall)if (precision+recall) > 0 else 0\n",
    "    print(f\"accuracy={accuracy}\")\n",
    "    print(f\"precision={precision}\")\n",
    "    print(f\"recall={recall}\")\n",
    "    print(f\"F1={F1}\")\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch2] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
